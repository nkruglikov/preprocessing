\documentclass[twoside]{article}
\usepackage{mmro14}
%\NOREVIEWERNOTES

\begin{document}
\title{Метод распознавания редких событий}
\author{Лбов~Г.\,С., Герасимов~М.\,К.}
\thanks{Работа выполнена при финансовой поддержке РФФИ, проект \No\,07-01-00331а.}
\email{lbov@math.nsc.ru, max\_post@ngs.ru}
\organization{Новосибирск, Институт математики СО РАН}
\abstract{
    В работе предложен метод построения модели для распознавания (прогнозирования) редких событий и~явлений.
    Предполагается, что редкие события могут описываться как количественными,
    так и качественными переменными. При анализе разнотипной
    информации введено взвешенное расстояние (мера близости).
    Для~нахождения оптимальных весов предложен метод адаптивного поиска приближенного значения глобального экстремума
    функции на симплексе.
    }
\maketitle

При анализе и прогнозировании реальных редких событий и явлений следует учитывать следующие особенности:
\begin{enumerate*}
    \item {методы прогнозирования должны использовать комплексное описание, содержащее как можно более полную
информацию обо всех факторах, потенциально влияющих на возникновение редких событий;}
    \item {реальные данные могут содержать не только количественную, но и качественную информацию;}
    \item {количество соответствующих редким событиям прецедентов в эмпирической информации мал\'о
по отношению к общему объёму выборки.}
\end{enumerate*}

\section{Постановка задачи}
Пусть объекты из некоторой генеральной совокупности $\Gamma$ описываются набором
переменных ${X=\{X_1,\ldots,X_n\}}$.
Данный набор может одновременно содержать
как количественные, так и качественные переменные.
Каждому объекту исследования
$a\in\Gamma$ поставлены в~соответствие номер образа 
$Y(a)\in \{ 1,\ldots,K \}$ и набор значений
$X(a)=\bigl(X_1(a),\ldots, X_n(a)\bigr)$, где $X_j(a)$
"--- значение переменной~$X_j$ для объекта~$a$.  Обозначим
через~$D_j$ множество возможных значений переменной~$X_j$.
Декартово произведение $D=\prod\limits_{j=1}^n D_j$  задаёт многомерное
пространство разнотипных переменных.

Без ограничения общности будем предполагать, что распознаются два образа,
$K=2$, а редкие события относятся к~первому образу. Предполагается, что
количество наблюдений редких событий в~эмпирической информации мал\'о
по~отношению к~общему объёму выборки, а возможные потери от ошибочного
предсказания второго образа достаточно велики.

Обозначим множество номеров объектов первого образа через~$I_1$, второго
образа "--- через~$I_2$:
$$
I_1=\left\{i\colon Y(a^i)=1\right\},\quad I_2=\left\{i\colon Y(a^i)=2\right\}.
$$

Пусть для нового объекта $a^*\in \Gamma$ измерены наблюдения по набору~$X$.
Необходимо отнести объект~$a^*$ к тому или иному образу, то есть оценить~$Y(a^*)$.
Предполагается, что распределение $\Prob(X,Y)$  неизвестно, следовательно, необходимо
определить принадлежность объекта на основе анализа обучающей выборки.

\section{Критерий распознавания\\ редких событий}
Применение методов распознавания образов для определения редких
событий в~данной постановке задачи затруднительно ввиду малого числа
соответствующих прецедентов в~обучающей \mbox{выборке}. Для решения задачи
будем использовать взвешенное расстояние между объектами~$a^i$
и~$a^l$:
$$
\rho^{il}=\sqrt{\sum_{j=1}^n \lambda_j \left(\rho_j^{il}\right)^2},
$$
где $\sum\limits_{j=1}^n \lambda_j {=}1$,\: $\lambda_j{\geq} 0$,\:
$j=1,\ldots,n$; \: $\rho_j^{il}$ "--- расстояние между
объектами~$a^i$ и~$a^l$ по $j$-й~компоненте набора~$X$, задаётся
в~зависимости от типа переменной~$X_j$: если $X_j$  "---
количественная, то $\rho_j^{il}\brop=\left|X_j(a^i)-X_j(a^l)\right|$;\:
если $X_j$  "--- качественная, то~$\rho_j ^{il}\brop= 0$ при
$X_j(a^i)=X_j(a^l)$ и $\rho_j ^{il} = 1$ при $X_j(a^i)\brop\neq
X_j(a^l)$.

Будем использовать следующую гипотезу:
предполагается, что существует такой набор значений коэффициентов $\lambda_j$ (<<весов>>), при котором
объекты первого образа, относящиеся к~редким событиям, расположены компактно
в пространстве~$D$, при этом достаточно сильно отличаясь от объектов второго образа.
Исходя из этой гипотезы, можно поставить следующую оптимизационную задачу:
необходимо подобрать коэффициенты $\lambda_j$ таким образом, чтобы минимизировать величину
$$r_1(\lambda_1,\ldots,\lambda_n)=\sum_{i,k\in I_1\colon i<k} \!\!\!\!\rho^{ik},$$ одновременно
максимизируя величину
$$r_2(\lambda_1,\ldots,\lambda_n)=\sum_{i\in I_1}\sum_{k\in I_2} \rho^{ik}.$$

В данной работе будем минимизировать следующий критерий:
$$f(\lambda_1,\ldots,\lambda_n)=\frac{r_1(\lambda_1,\ldots,\lambda_n)}
{c+r_2(\lambda_1,\ldots,\lambda_n)}, \quad c=\const>0.$$

Определив взвешенное расстояние в многомерном пространстве, можно по
степени близости к~объектам изучения оценить принадлежность новых
объектов к~тому или иному образу, например, методом ближайшего
соседа.

Подобного рода задача оптимизации возникает также и в~предложенном
в~работе~\cite{bibArticle1} методе прогнозирования экстремальных ситуаций, которые тоже
по своей сути являются редкими \mbox{событиями}.

\par
Заметим, что область значений коэффициентов $\lambda_1,\ldots,\lambda_n$ (обозначим её через~$\Lambda$)
представляет собой многомерный симплекс
\begin{multline*}
    \Lambda=
    \Bigl\{
        \lambda=(\lambda_1,\ldots,\lambda_n)
    \colon %\Bigm|
\\
        \sum_{j=1}^n \lambda_j =1,\; \lambda_j\geq 0,\; j=1,\ldots,n
    \Bigr\}
    \subset\RR^n.
\end{multline*}

При других способах задания расстояния (меры близости) между объектами могут быть получены
другие многомерные области.

\section{Подбор оптимальных весов}
Поскольку свойства функции $f(\lambda)$ в прикладных задачах распознавания редких событий
зависят от случайной выборки, то при решении указанной оптимизационной задачи
можно использовать лишь общие свойства класса $\{f(\lambda)\}$ в виде некоторой <<разумной>> гипотезы,
приведённой ниже.

Для нахождения оптимальных коэффициентов будем использовать
модификацию метода поиска приближенного значения глобального
экстремума функции~\cite{bibBook1, bibBook2}. Данный метод является
развитием метода СПА (случайного поиска с~адаптацией)~\cite{bibArticle2} для поиска наиболее
информативного подпространства признаков в задачах распознавания
образов. Заметим, что последующим обобщением метода СПА являются
генетические алгоритмы.

Рассмотрим функцию
$f(\lambda)$,\:  $\lambda\in\Lambda$.
Обозначим  $\lambda^*=\arg\min_{\lambda\in\Lambda}f(\lambda)$.   Пару
$\left\langle \lambda^{i},f(\lambda^{i} )\right \rangle$ будем называть  испытанием. Под алгоритмом
поиска приближенного значения глобального минимума функции понимается
некоторая процедура последовательного планирования $N$~испытаний
с~целью нахождения  минимально  возможного  значения  функции.


Общее число испытаний~$N$ разбивается на $R$ групп:
$ N=N_{1} + \ldots +N_{R}.$

Обозначим через $N^{\nu}=\sum\limits_{i=1}^{\nu}N_{i}$ "--- число
испытаний, проведенных за $\nu$~шагов поиска (под шагом поиска
понимается проведение  $N_{i}$~испытаний), ${\nu=1,\ldots,R}$.
Первая группа испытаний планируется таким образом, чтобы для
любого $E\subset  \Lambda$  число  испытаний, соответствующее множеству~$E$,
было бы примерно равно $\frac{N_{1} V(E)}{V(D)}$, где $V(E)$ "--- объём области~$E$.
Другими словами, точки $\lambda^{1},\ldots,\lambda^{N_{1}}$ планируем таким
образом, чтобы они были бы максимально равномерно  распределены по множеству~$\Lambda$.


Для вычисления объёмов в предлагаемом методе используется метод Монте"=Карло.
Как показано в~работе~\cite{bibBook3}, метод Монте"=Карло эффективен для вычисления
многомерных интегралов, в~частности "--- объёмов. Кроме того, метод Монте"=Карло позволяет
вычислять объёмы и для более сложных, чем симплекс, областей.


Пусть проведено $N^{\nu}$~испытаний, $\nu=1,\ldots,R{-}1$, и получена
соответствующая таблица $v^{\nu}=\{\lambda^{i},f(\lambda^{i})\}$,\; $i=1,\ldots,N^{\nu}$.
С~помощью алгоритма LRP (см., например,~\cite{bibBook1}) построим наилучшую регрессионную
функцию~$\bar{f}^{\nu}$ в классе логических решающих функций.
Функции~$\bar{f}^{\nu}$
соответствует некоторое разбиение множества~$\Lambda$:\; $a_{\nu}=\{E^{1}_{\nu},\ldots,
E^{M_{\nu}}_{\nu}\}$.
Множества $E^{t}_{\nu}$ имеют вид
$$E^{t}_{\nu}=\bigl\{ \lambda\in\Lambda\colon c_j \leq \lambda_j \leq d_j,\enskip j=1,\ldots,n \bigr\}.$$

Будем использовать следующую гипотезу: вероятность достижения глобального минимума функции
в~области~$E$  зависит от числа проведённых испытаний, объёма множества $E$ и результатов
проведённых ранее в~точках множества $E$ испытаний. Предполагается, что чем больше объём
множества~$E$ (а, значит, и неисследованность) и меньше по сравнению с~другими областями
полученные при испытаниях значения функции, тем больше вероятность достижения глобального
минимума в~этом множестве.


Введём вспомогательную функцию
$$\kappa_{b}(z)=\frac{b+1}{(1+bz)^{2}},\quad 0 \leq z \leq 1,
\quad 0  \leq b \leq \infty.$$
Выбор этой функции определяется следующими её свойствами:
\begin{enumerate*}
    \item {при $b=0$ получаем $\kappa_{b}(z)=1$;}
    \item {при $b>0$ получаем монотонно убывающую функцию по $z$;}
    \item {чем больше значение параметра  $b$, тем больше скорость
убывания функции по $z$;}
    \item {$\int\limits_{0}^{1}\kappa_{b}(z)dz=1$ при любом $b$.}
\end{enumerate*}

Данные свойства функции $\kappa_{b}(z)$ позволяют формализовать
вышеуказанную гипотезу. Отметим, что в качестве функции $\kappa_{b}(z)$ можно
выбрать любую функцию, удовлетворяющую этим свойствам.

Зададим функцию
$$ \kappa^{u}=\int\limits_{0}^{u}\kappa_{b}(z)dz=
\frac{(b+1)u}{1+bu},\quad 0 \leq u \leq 1.$$

Определим вероятности $p^{t}_{\nu}$ проведения испытания в~множествах~$E^{t}_{\nu}$,
\: $t=1,\ldots,M_\nu$.
Обозначим через $f^{t}_{\min}$ минимальное значение функции~$f$
при~проведённых испытаниях в множестве~$E^{t}_{\nu}$.
Пусть $f^{t_1}_{\min}\leq \ldots\leq f^{t_{M_\nu}}_{\min}$.
По оси~$z$ будем откладывать последовательно величины~$z^i$, равные
относительным объёмам соответствующих множеств:
 $$z^i=\frac{V(E^{t_i}_{\nu})}{V(D)}, \quad i=1,\ldots,M_\nu,$$
то есть первоначально откладывается относительный объём наилучшего
множества $E^{t_{1}}_{\nu}$, которому соответствует $f_{\min}^{t_{1}}$, затем
относительный объём второго по порядку множества $E^{t_{2}}_{\nu}$,
которому соответствует $f_{\min}^{t_{2}}$ и т.~д. Таким образом, отрезок $[0,1]$ на
оси~$z$ разбивается на $M_{\nu}$~отрезков. Вероятности~$p^{t}_{\nu}$
определяются  по формуле
\begin{align*}
    p^{t}_{\nu}
    &=
    \kappa^{u_{t+1}}{-}\kappa^{u_{t}}
    =
    \int\limits_{0}^{u_{t+1}}\!\!\! \kappa_{b}(z)\,dz -
    \int\limits_{0}^{u_{t}}\!\! \kappa_{b}(z)\,dz
    ={}
\\
    &=
    \frac
        {(b+1)(u_{t+1}-u_{t})}
        {(1+bu_{t+1})(1+bu_{t})}, 
    \quad t=1,\ldots,M_\nu.
\end{align*}


Таким образом, чем больше объём множества~$E^{t}_{\nu}$ и
меньше номер~$i$, определяющий номер этого множества в~порядке
$E^{t_{1}}_{\nu},\ldots,E^{t_{M_\nu}}_{\nu}$, тем больше
вероятность $p^{t}_{\nu}$ (в~соответствии с~указанной выше гипотезой).
Зададим линейную зависимость параметра~$b$ от числа проведенных испытаний
$N^{\nu}$, то~есть на $\nu +1$~шаге поиска будем использовать величину
$b^{\nu}=\frac{N^{\nu}}{N}b_{\max}$. Величина $b_{\max}$
определяется из следующих соображений. После проведения всех испытаний
($N^{R}=N$) в~соответствии с~гипотезой можно указать область $E(\gamma)$
такую, что вероятность нахождения точки $\lambda^*$ равна
$p(\gamma)\simeq 1$. При~этом область $E(\gamma)$ достаточно мала, то есть
$\gamma=\frac{V(E(\gamma))}{V(D)} \simeq 0$. Например,
$p(\gamma)=0{,}95$, а $\gamma =0{,}05$.
Величина $b_{\max}$ определяется из следующего соотношения:
$$ p(\gamma)=\int\limits_{0}^{\gamma}\!\kappa_{b}(z)\,dz=
\frac{(b_{\max}+1)\gamma}{1+b_{\max}\gamma}.
$$


Предложенный метод поиска приближенного значения глобального
экстремума функции может быть использован для любого множества, где
возможно эффективное использование метода Монте"=Карло. Таким
образом, область оптимизации может представлять собой не только
многомерный симплекс, но и, например, гиперсферу.

\section{Пример решения прикладной задачи}
Разработанные в рамках данного подхода методы были использованы для
прогноза экстремальных ситуаций на реках Сибири~\cite{bibArticle1}.
В~частности, оценивалось возникновение в~марте экстремальной по
маловодью ситуации в~контрольной точке <<Барнаул>>. Были обработаны
среднемесячные данные замеров стока реки Обь за период с~1937 по~1990~гг. 
Использовались следующие дополнительные характеристики:
температура воздуха и~количество выпавших осадков (станции "---
<<Онгудай>>  и <<Волчиха>>) за сентябрь и октябрь предыдущего года.
Данные с 1991 по 2000 гг. использовались для контроля. За этот
период было одно маловодье (1998~г.). Был сделан верный прогноз
маловодья на 1998 год и неверный на 1999 год. В~остальные годы
правильно предсказано отсутствие маловодья. Необходимо подчеркнуть,
что имеющаяся информация представляет собой числовые
(количественные) временные ряды, тогда как  разработанные методы
могут быть использованы для решения более общих задач, в~которых
информация об исследуемых событиях описывается как количественными,
так и качественными \mbox{характеристиками}.

\section{Выводы}
В работе предложен метод распознавания (прогнозирования) редких
событий. В методе используется тот факт, что количество наблюдений
редких событий в~эмпирической информации мало. Определив взвешенное
расстояние в многомерном пространстве, можно по степени близости к
объектам изучения оценить принадлежность новых объектов к~тому или
иному образу. Результаты решения прикладных задач показывают
эффективность метода прогнозирования редких событий.

\begin{thebibliography}{1}
\bibitem{bibArticle1}
    \BibAuthor{Лбов~Г.\,С., Герасимов~М.\,К.}
    \BibTitle{Прогнозирование экстремальных ситуаций на основе совместного анализа
    временных рядов и экспертных высказываний}~//
    Научный вестник НГТУ. "---
    2007. "---  \No\,3(28). "---   \mbox{С.~13--24}.
\bibitem{bibBook1}
\BibAuthor{Лбов\;Г.\,С.}
    Методы обработки разнотипных экспериментальных данных. "---
    Новосибирск:~Наука, 1981.
\bibitem{bibBook2}
\BibAuthor{Лбов\;Г.\,С., Старцева\;Н.\,Г.}
    Логические решающие функции и вопросы статистической устойчивости решений. "---
    Новосибирск:~Издательство Института математики, 1999. "--- 212~c.
\bibitem{bibArticle2}
    \BibAuthor{Лбов~Г.\,С.}
    \BibTitle{Выбор эффективной системы зависимых признаков}~//
    Вычислительные системы. "---
    1965. "---  Вып.~19. "---   С.~21--34.
\bibitem{bibBook3}
    \BibAuthor{Бусленко\;Н.\,П., Голенко\;Д.\,И., Соболь\;И.\,М., Срагович\;В.\,Г., Шрейдер\;Ю.\,А.}
    Метод статистических испытаний (метод Монте"=Карло). "---
    Москва:~Физматлит, %Государственное издательство физико"=математической литературы, 
    1962. "--- 332~с.

\end{thebibliography}

\end{document}
